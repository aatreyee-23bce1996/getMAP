# getMAP ðŸ›°ï¸

> **AI-powered spatial downscaling of tropospheric NOâ‚‚ satellite maps**  
> Software Engineering Lab Â· BCSE301P Â· SIH Problem Statement

[![Python](https://img.shields.io/badge/Python-3.11+-3670A0?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.42+-FF4B4B?style=flat-square&logo=streamlit&logoColor=white)](https://streamlit.io)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.6+-F7931E?style=flat-square&logo=scikit-learn&logoColor=white)](https://scikit-learn.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-006400?style=flat-square)](https://xgboost.readthedocs.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)

---

## What is getMAP?

getMAP is a full-stack ML application that takes **coarse-resolution satellite NOâ‚‚ data** (3.5 km from TROPOMI/Sentinel-5P or 13 km from OMI/Aura) and generates **fine-resolution air quality maps** using machine learning â€” up to 8Ã— sharper than the raw input.

It addresses a real gap: while individual tools exist for satellite processing and ML modelling, no comprehensive, validated, end-to-end solution exists for NOâ‚‚ downscaling. getMAP closes that gap.

**Problem statement:** SIH â€” Downscaling of Satellite-based Air Quality Maps using AI/ML  
**Desired output:** Fine spatial resolution tropospheric NOâ‚‚ map of India, validated against CPCB ground station data.

---

## Table of Contents

1. [Features](#features)
2. [Architecture](#architecture)
3. [Prerequisites](#prerequisites)
4. [Installation](#installation)
5. [Configuration (.env)](#configuration)
6. [Running the App](#running-the-app)
7. [App Walkthrough](#app-walkthrough)
8. [Data Sources](#data-sources)
9. [ML Algorithms](#ml-algorithms)
10. [Project Structure](#project-structure)
11. [Validation & Metrics](#validation--metrics)
12. [Export & Results](#export--results)

---

## Features

- **Three ML algorithms** â€” Random Forest, XGBoost, Gradient Boosting; switchable from the UI
- **Cloudy-pixel gap filling** â€” spatial interpolation or mean-fill before training
- **7-dimensional feature engineering** â€” spatial coordinates, local mean/std (3Ã—3 window), row & column gradients
- **Up to 8Ã— resolution enhancement** â€” bicubic pre-upsampling + ML refinement
- **Interactive Plotly maps** â€” zoom, pan, hover tooltips on both original and downscaled grids
- **Side-by-side comparison** â€” original coarse vs. downscaled fine resolution on the same colour scale
- **Feature importance chart** â€” understand which spatial features drive predictions
- **CPCB ground truth validation** â€” upload CSV from CPCB Advanced Search; records saved to database
- **Metrics dashboard** â€” MSE, RMSE, MAE, RÂ², Bias with colour-coded quality indicator
- **One-click CSV export** â€” download the downscaled map and metrics for your report
- **Demo mode** â€” try everything without uploading any data

---

## Architecture

```
getMAP/
â”œâ”€â”€ main.py          â† Streamlit frontend + orchestration
â”œâ”€â”€ model.py         â† ML model (RF / XGBoost / GBM) with feature engineering
â”œâ”€â”€ utils.py         â† Data I/O, visualisation, metrics
â”œâ”€â”€ database.py      â† SQLAlchemy ORM (SQLite by default)
â”œâ”€â”€ index.html       â† Standalone presentation/demo landing page
â”œâ”€â”€ styles.css       â† Streamlit custom CSS (auto-loaded)
â”œâ”€â”€ pyproject.toml   â† Dependency manifest
â””â”€â”€ .env             â† Your local config (not committed to git)
```

**Pipeline flow:**

```
GeoTIFF upload          CPCB CSV upload
      â”‚                       â”‚
      â–¼                       â–¼
 load_satellite_data    load_ground_data
      â”‚                       â”‚
      â–¼                       â–¼
 handle_missing_data    save_ground_measurements
 (gap fill NaN/clouds)
      â”‚
      â–¼
 NO2DownscalingModel.train()
 â”œâ”€â”€ prepare_features()  â†’ 7-dim feature vectors
 â”œâ”€â”€ StandardScaler      â†’ normalise features
 â””â”€â”€ RF / XGB / GBM fit on 80% of valid pixels
      â”‚
      â–¼
 NO2DownscalingModel.predict(scale_factor)
 â”œâ”€â”€ bicubic zoom to target resolution
 â””â”€â”€ ML refinement on fine-resolution grid
      â”‚
      â–¼
 calculate_metrics()    create_comparison_plot()
      â”‚                       â”‚
      â–¼                       â–¼
  Metrics display        Plotly heatmaps
      â”‚
      â–¼
  CSV download
```

---

## Prerequisites

- Python **3.11 or newer**
- pip (comes with Python)
- ~500 MB disk space (for dependencies)
- Internet connection for first install

Optional but recommended: [Google Earth Engine account](https://earthengine.google.com/) for downloading TROPOMI GeoTIFFs directly.

---

## Installation

**Do not run `pip install .`** â€” the flat project layout causes setuptools to error. Install dependencies directly instead.

### Step 1 â€” Clone / download the project

```bash
# If using git
git clone https://github.com/your-username/getmap.git
cd getmap

# Or just unzip and navigate to the folder
cd C:\Users\nanda\Downloads\swelab
```

### Step 2 â€” (Optional but recommended) Create a virtual environment

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate
```

### Step 3 â€” Install dependencies

```bash
pip install streamlit numpy pandas plotly scikit-learn xgboost scipy rasterio sqlalchemy python-dotenv matplotlib Pillow
```

This installs everything getMAP needs. The full list is also in `pyproject.toml` for reference.

---

## Configuration

Create a file named **`.env`** in the root project folder (same folder as `main.py`):

```
DATABASE_URL=sqlite:///./getmap.db
```

That's the only line you need. SQLite creates the database file automatically on first run.

---

## Running the App

From inside the project folder with your virtual environment active:

```bash
streamlit run main.py
```

Streamlit will print something like:

```
  You can now view your Streamlit app in your browser.
  Local URL: http://localhost:8501
```

Open **http://localhost:8501** in your browser. The app is ready.

> **Presentation page:** Open `index.html` directly in any browser (double-click the file) for a standalone landing page that describes the project â€” useful for demos and lab presentations without needing the Streamlit server running.

---

## App Walkthrough

### 1. Sidebar â€” Configure the model

On the left side of the app you'll find three controls:

| Control | What it does |
|---|---|
| **Algorithm** | Choose between Random Forest, XGBoost (recommended), or Gradient Boosting |
| **Upscaling factor** | How much finer the output is. 4Ã— means a 64Ã—64 grid becomes 256Ã—256 |
| **Gap-fill method** | How to handle cloudy pixels (NaN). Interpolate is usually better |
| **Use demo data** | Generates synthetic NOâ‚‚ data so you can try everything without uploading |

---

### 2. Upload your data

The main area has two upload boxes:

**Left box â€” Satellite Data (GeoTIFF)**  
Upload a `.tif` or `.tiff` file exported from TROPOMI/Sentinel-5P or OMI/Aura. Single-band NOâ‚‚ column density. See [Data Sources](#data-sources) for where to get this.

**Right box â€” Ground Station Data (CSV)**  
Upload a CSV downloaded from the CPCB Advanced Search. The file needs these columns (case-insensitive): `latitude`, `longitude`, `no2_value`, `station_name`. Extra columns are ignored.

> **No data yet?** Tick **"Use demo data"** in the sidebar to generate a synthetic 64Ã—64 NOâ‚‚ grid and see the full pipeline in action.

---

### 3. Input data preview

Once data loads, you'll see:

- Four stat tiles showing **grid size**, **% cloudy pixels**, **min NOâ‚‚**, and **max NOâ‚‚**
- An interactive **Plotly heatmap** of the original coarse-resolution input
- If you uploaded ground station CSV, a confirmation message and a preview table

---

### 4. Run downscaling

Click the **"ðŸš€ Run Downscaling"** button. A progress bar tracks the stages:

1. Model initialisation
2. Feature preparation (7 spatial features per valid pixel)
3. Training on 80% of pixels (the held-out 20% is used for validation)
4. High-resolution prediction on the upscaled grid
5. Metric computation

---

### 5. Metrics dashboard

After training, four metric tiles appear:

| Metric | Good range | Meaning |
|---|---|---|
| **RÂ² Score** | â‰¥ 0.85 | Fraction of variance explained. Closer to 1.0 is better |
| **RMSE** | As low as possible | Root mean squared error in NOâ‚‚ units |
| **MAE** | As low as possible | Mean absolute error â€” less sensitive to outliers than RMSE |
| **Bias** | Near 0 | Systematic over/under-prediction |

A colour-coded banner tells you at a glance: ðŸŸ¢ Excellent (RÂ² â‰¥ 0.85), ðŸŸ¡ Acceptable (â‰¥ 0.65), ðŸ”´ Poor (< 0.65).

---

### 6. Feature importance

Click the **"ðŸ“Š Feature importance"** expander to see which of the 7 input features the model relied on most. For NOâ‚‚ data, `NO2 Value` and `Local Mean` typically dominate, which makes physical sense â€” nearby pixel values are the strongest predictor of a pixel's fine-resolution value.

---

### 7. Resolution comparison

A side-by-side Plotly figure shows the **original coarse** grid (left) next to the **downscaled fine** grid (right) on identical colour scales. Both are interactive â€” zoom into an urban area to see the sharpening clearly.

Below it, a full-width view of the downscaled map with the chosen upscaling factor in the title.

---

### 8. Export results

Two download buttons appear at the bottom:

- **ðŸ“¥ Download CSV** â€” the downscaled NOâ‚‚ grid as a CSV matrix (rows Ã— columns)
- **ðŸ“¥ Download Metrics** â€” MSE, RMSE, MAE, RÂ², Bias in a single-row CSV for your lab report

---

## Data Sources

### Satellite NOâ‚‚ (pick one)

| Source | Resolution | Format | Link |
|---|---|---|---|
| TROPOMI/Sentinel-5P (NASA Earthdata) | 3.5 km | HDF5 swath | [Earthdata search](https://search.earthdata.nasa.gov/search/granules?p=C2089270961-GES_DISC&pg[0][v]=f&pg[0][gsk]=-start_date&q=tropomi%20no2&tl=1726635700.002!3!!) |
| TROPOMI/Sentinel-5P (Google Earth Engine) | 3.5 km | GeoTIFF âœ… | [GEE catalogue](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_NO2#description) |
| OMI/Aura (NASA Earthdata) | 13 km | HDF4 gridded | [Earthdata search](https://search.earthdata.nasa.gov/search/granules?p=C1266136111-GES_DISC&pg[0][v]=f&pg[0][gsk]=start_date&q=omi%20tropospheric%20no2&tl=1726635700.002!3!!) |
| OMI/Aura MINDS (direct download) | 13 km | NetCDF gridded | [GES DISC](https://measures.gesdisc.eosdis.nasa.gov/data/MINDS/OMI_MINDS_NO2d.1.1/2024/) |

### Ground station NOâ‚‚ (CPCB)

1. Go to [CPCB CCMS](https://app.cpcbccr.com/ccr/#/caaqm-dashboard-all/caaqmlanding)
2. Click **Advanced Search**
3. Select parameter: **NO2**, frequency: **Daily**
4. Choose your date range and stations
5. Download as CSV
6. Rename columns to `latitude`, `longitude`, `no2_value`, `station_name` if needed

---

## ML Algorithms

getMAP implements three algorithms, all selectable from the sidebar:

### Random Forest (default fallback)
- 200 trees, max depth 12
- Robust to satellite data outliers and cloud-gap noise
- Provides feature importance out of the box
- No extra installation needed

### XGBoost â­ Recommended
- 200 estimators, max depth 6, learning rate 0.1
- Sub-sampling regularisation reduces overfitting
- Consistently best RÂ² on spatial regression tasks
- Requires `xgboost` package (included in install command above)

### Gradient Boosting
- 150 estimators, max depth 5, learning rate 0.1
- Sequential tree building reduces model bias
- Good middle ground â€” slower to train but no extra dependency

### Features used by all models

| Feature | Description |
|---|---|
| Normalised row | Pixel's y-position as fraction of grid height |
| Normalised col | Pixel's x-position as fraction of grid width |
| NOâ‚‚ value | Raw input NOâ‚‚ column density |
| Local mean | Mean of 3Ã—3 neighbourhood window |
| Local std | Standard deviation of 3Ã—3 neighbourhood |
| Row gradient | Spatial rate of change in y direction |
| Col gradient | Spatial rate of change in x direction |

---

## Project Structure

```
getmap/
â”‚
â”œâ”€â”€ main.py              # Streamlit app â€” UI, upload handling, orchestration
â”œâ”€â”€ model.py             # NO2DownscalingModel class
â”‚   â”œâ”€â”€ __init__         # Initialise chosen algorithm + StandardScaler
â”‚   â”œâ”€â”€ prepare_features # Build 7-dim feature matrix from 2D NOâ‚‚ array
â”‚   â”œâ”€â”€ train            # 80/20 split â†’ fit â†’ return val set
â”‚   â”œâ”€â”€ predict          # Bicubic upsample â†’ ML refine â†’ return fine grid
â”‚   â””â”€â”€ get_feature_importance
â”‚
â”œâ”€â”€ utils.py             # Helper functions
â”‚   â”œâ”€â”€ load_satellite_data    # rasterio GeoTIFF reader
â”‚   â”œâ”€â”€ load_ground_data       # CPCB CSV reader with column normalisation
â”‚   â”œâ”€â”€ handle_missing_data    # NaN gap-fill (interpolate or mean)
â”‚   â”œâ”€â”€ save_satellite_data    # Sampled pixel persist to DB
â”‚   â”œâ”€â”€ save_ground_measurements
â”‚   â”œâ”€â”€ create_no2_map         # Plotly heatmap
â”‚   â”œâ”€â”€ create_comparison_plot # Side-by-side Plotly figure
â”‚   â”œâ”€â”€ calculate_metrics      # MSE, RMSE, MAE, RÂ², Bias
â”‚   â””â”€â”€ generate_demo_data     # Synthetic NOâ‚‚ for testing
â”‚
â”œâ”€â”€ database.py          # SQLAlchemy models + session factory
â”‚   â”œâ”€â”€ SatelliteData    # Table: sampled satellite pixels
â”‚   â””â”€â”€ GroundMeasurement # Table: CPCB station readings
â”‚
â”œâ”€â”€ index.html           # Standalone landing page (open in browser directly)
â”œâ”€â”€ styles.css           # Custom Streamlit CSS (dark theme)
â”œâ”€â”€ pyproject.toml       # Project metadata and dependency list
â””â”€â”€ .env                 # Your local environment variables (create this yourself)
```

---

## Validation & Metrics

getMAP uses a strict **80/20 spatial train-test split**. The 20% held-out pixels are never seen during training â€” this satisfies the SIH requirement of validating on "unseen independent data."

**Interpreting RÂ²:**

| RÂ² | Interpretation |
|---|---|
| 0.90 â€“ 1.00 | Excellent â€” model captures spatial structure well |
| 0.75 â€“ 0.90 | Good â€” suitable for most research applications |
| 0.65 â€“ 0.75 | Acceptable â€” consider more training data or XGBoost |
| < 0.65 | Poor â€” likely insufficient spatial variation in input data |

---

## Export & Results

After running downscaling, two files can be downloaded from the app:

**`no2_downscaled.csv`** â€” The high-resolution NOâ‚‚ grid as a matrix. Each row is a latitude slice, each column is a longitude slice. Values are in mol/mÂ² (same units as input).

**`model_metrics.csv`** â€” A single row with columns: `MSE`, `RMSE`, `MAE`, `R2`, `Bias`. Paste this directly into your lab report.

Both files are also auto-saved to the SQLite database (`getmap.db`) during each session.

---

## Team

**SWELAB Â· BCSE301P** â€” VIT  
Built for Software Engineering Lab, problem statement taken from SIH 2024: *Downscaling of Satellite-based Air Quality Maps using AI/ML*

---

*Data: ESA/NASA TROPOMI Sentinel-5P Â· OMI/Aura GES DISC Â· CPCB CCMS India*